{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import SequentialChain, LLMChain\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "template1 = \"\"\"You are expert software analyst, you can easily split and classify entity from sentence \n",
    "- Categorized as CORE if the entity is a specific feature of software requirement domain, example (system, application, payment, login) \n",
    "- Categorized as USER if the entity is a specific user of the software, example (Admin, developer, Student, customer, buyer, cashier) \n",
    "- Categorized as HARDWARE if the entity is a component of computer hardware, example (Keyboard, mouse, CPU) \n",
    "- Categorized as PLATFORM if the entity is a third party application or software platform, example (Linux, Paypal, eBay, Apache) \n",
    "\n",
    "Given sentence : {sentence}\n",
    "\n",
    "- Output must separated by comma like [entity],[category]\n",
    "- Each line is separated by '\\n'\n",
    "- Don't display anything in the output except the output csv format\n",
    "\n",
    "\"\"\"\n",
    "template2 = \"\"\"From the output of extraction\n",
    "^^^\n",
    "{extraction}\n",
    "^^^\n",
    "extraction format is seperated by comma like [entity],[category]\n",
    "\n",
    "and in context sentence : $$$\n",
    "{sentence}\n",
    "$$$\n",
    "\n",
    "- Generate semantic triple that consist subject, predicate, and object from entities (which is delimited by ^^^)  base on context sentence (which is delimited by $$$) \n",
    "- Output must separated by comma the format is [entity],[predicate],[entity]\n",
    "- Each line is separated by '\\n'\n",
    "- Don't display anything in the output except the output csv format\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_template(template1)\n",
    "prompt2 = ChatPromptTemplate.from_template(template2)\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", api_key=os.getenv('OPEN_API_KEY'), temperature=0)\n",
    "\n",
    "chain1 = prompt1 | model\n",
    "chain2 = prompt2 | model\n",
    "\n",
    "chain_one = LLMChain(llm=model, prompt=prompt1, output_key=\"extraction\")\n",
    "chain_two = LLMChain(llm=model, prompt=prompt2, output_key=\"triple\")\n",
    "\n",
    "overal_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two],\n",
    "    input_variables=[\"sentence\"],\n",
    "    output_variables=[\"extraction\", \"triple\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"With Odoo Point of Sale, run your shops and restaurants easily. The app works on any device with a web browser, even if you are temporarily offline. Product moves are automatically registered in your stock, you get real-time statistics, and your data is consolidated across all shops\"\n",
    "app_name = \"Odoo POS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = overal_chain({\"sentence\": sentence})\n",
    "ner = message['extraction'].split('\\n')\n",
    "triples = message['triple'].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Odoo Point of Sale,runs,shops  ', 'Odoo Point of Sale,runs,restaurants  ', 'The app,works on,device  ', 'The app,works on,web browser  ', 'Product,moves,stock  ', 'You,get,real-time statistics  ', 'You,consolidate,data  ', 'You,consolidate,shops  ']\n"
     ]
    }
   ],
   "source": [
    "print(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>predicate</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Odoo Point of Sale</td>\n",
       "      <td>runs</td>\n",
       "      <td>shops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Odoo Point of Sale</td>\n",
       "      <td>runs</td>\n",
       "      <td>restaurants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The app</td>\n",
       "      <td>works on</td>\n",
       "      <td>device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The app</td>\n",
       "      <td>works on</td>\n",
       "      <td>web browser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Product</td>\n",
       "      <td>moves</td>\n",
       "      <td>stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>You</td>\n",
       "      <td>get</td>\n",
       "      <td>real-time statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>You</td>\n",
       "      <td>consolidate</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>You</td>\n",
       "      <td>consolidate</td>\n",
       "      <td>shops</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              subject    predicate                  object\n",
       "0  Odoo Point of Sale         runs                 shops  \n",
       "1  Odoo Point of Sale         runs           restaurants  \n",
       "2             The app     works on                device  \n",
       "3             The app     works on           web browser  \n",
       "4             Product        moves                 stock  \n",
       "5                 You          get  real-time statistics  \n",
       "6                 You  consolidate                  data  \n",
       "7                 You  consolidate                 shops  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "split_data = [item.split(',') for item in triples]\n",
    "df = pd.DataFrame(split_data, columns=['subject', 'predicate', 'object'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_inverse_key(obj, key):\n",
    "    return next((k for k, v in obj.items() if v == key), None)\n",
    "\n",
    "def triplet_unique_flatten(data):\n",
    "    flattened_unique = []\n",
    "    for triplet in data:\n",
    "        for element in triplet:\n",
    "            if element not in flattened_unique:\n",
    "                flattened_unique.append(element)\n",
    "    return flattened_unique\n",
    "\n",
    "def df_map_to_cql(df):\n",
    "    entities = []\n",
    "    for index, row in df.iterrows():\n",
    "        if (row['subject'] in entities) == False:\n",
    "            entities.append(row['subject'].strip())\n",
    "        if (row['object'] in entities) == False:\n",
    "            entities.append(row['object'].strip())\n",
    "    verbObj = {}\n",
    "    for index, row in df.iterrows():\n",
    "        verbObj[row['predicate'].strip()] = f'r{index}'\n",
    "\n",
    "    init = 'a'\n",
    "    entityObj = {}\n",
    "    for i in range(len(entities)):\n",
    "        char = chr(ord(init) + i)\n",
    "        entityObj[entities[i]] = char\n",
    "\n",
    "    xyz = []\n",
    "    for _, row in df.iterrows():\n",
    "        subjek = entityObj[row['subject'].strip()]\n",
    "        objek = entityObj[row['object'].strip()]\n",
    "        predicate = verbObj[row['predicate'].strip()]\n",
    "        xyz.append([subjek, predicate, objek])\n",
    "    return xyz, entityObj, verbObj\n",
    "\n",
    "def arr_map_to_cql(arr, flattenArr):\n",
    "    cql_string = \"\"\n",
    "    for i in range(len(arr)):\n",
    "        cql_string += f\"MATCH ({arr[i][0]})-[{arr[i][1]}:RELATED_TO]->({arr[i][2]}) \\n\"\n",
    "    cql_string += \"WHERE a.app = $app_name WITH \"\n",
    "    for i in range(len(flattenArr)):\n",
    "        cql_string += f\"vector.similarity.cosine({flattenArr[i]}.embedding, $embed_{flattenArr[i]}) as score_{flattenArr[i]}, \"\n",
    "    cql_string += \"a.id as id, a.feature as feature, a.app as app \\n WITH id, feature, app, (\"\n",
    "    for i in range(len(flattenArr)):\n",
    "        cql_string += f\"score_{flattenArr[i]}+\"\n",
    "    cql_string = cql_string[:-1]\n",
    "    cql_string += f\")/{len(flattenArr)} as score RETURN id, MAX(score) as score ORDER BY score DESC LIMIT 10\"\n",
    "    return cql_string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MATCH (n)-[r:RELATED_TO]->(m)\n",
    "WITH n.name as subject, m.name as object, r.type as verb, n.app as app, n.feature as feature, vector.similarity.cosine(n.embedding, $embed_one) as subjectScore, \n",
    "    vector.similarity.cosine(m.embedding, $embed_two) as objectScore,\n",
    "     vector.similarity.cosine(r.embedding, $embed_verb) as verbScore\n",
    "RETURN subject, object, verb, app, feature, ((subjectScore * 0.5) + (objectScore * 0.3) + (verbScore * 0.2)) as score\n",
    "ORDER BY score DESC LIMIT 10\n",
    "\n",
    "MATCH (n {name: \"real-time statistics\"})-[r:RELATED_TO {type: \"provide\"}]->(p {name: \"data\"})\n",
    "MATCH (x {name: \"data\"})-[r2:RELATED_TO {type: \"is consolidated across\" }]->(y {name: \"shops\"})\n",
    "return *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MATCH (a)-[r1:RELATED_TO]->(l) \\nMATCH (a)-[r1:RELATED_TO]->(c) \\nMATCH (d)-[r3:RELATED_TO]->(e) \\nMATCH (d)-[r3:RELATED_TO]->(f) \\nMATCH (g)-[r4:RELATED_TO]->(h) \\nMATCH (i)-[r5:RELATED_TO]->(j) \\nMATCH (i)-[r7:RELATED_TO]->(k) \\nMATCH (i)-[r7:RELATED_TO]->(l) \\nWHERE a.app = $app_name WITH vector.similarity.cosine(a.embedding, $embed_a) as score_a, vector.similarity.cosine(r1.embedding, $embed_r1) as score_r1, vector.similarity.cosine(l.embedding, $embed_l) as score_l, vector.similarity.cosine(c.embedding, $embed_c) as score_c, vector.similarity.cosine(d.embedding, $embed_d) as score_d, vector.similarity.cosine(r3.embedding, $embed_r3) as score_r3, vector.similarity.cosine(e.embedding, $embed_e) as score_e, vector.similarity.cosine(f.embedding, $embed_f) as score_f, vector.similarity.cosine(g.embedding, $embed_g) as score_g, vector.similarity.cosine(r4.embedding, $embed_r4) as score_r4, vector.similarity.cosine(h.embedding, $embed_h) as score_h, vector.similarity.cosine(i.embedding, $embed_i) as score_i, vector.similarity.cosine(r5.embedding, $embed_r5) as score_r5, vector.similarity.cosine(j.embedding, $embed_j) as score_j, vector.similarity.cosine(r7.embedding, $embed_r7) as score_r7, vector.similarity.cosine(k.embedding, $embed_k) as score_k, a.id as id, a.feature as feature, a.app as app \\n WITH id, feature, app, (score_a+score_r1+score_l+score_c+score_d+score_r3+score_e+score_f+score_g+score_r4+score_h+score_i+score_r5+score_j+score_r7+score_k)/16 as score RETURN id, MAX(score) as score ORDER BY score DESC LIMIT 10'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapTriplet, entityObj, verbObj = df_map_to_cql(df)\n",
    "flatten = triplet_unique_flatten(mapTriplet)\n",
    "cql_string = arr_map_to_cql(mapTriplet, flatten)\n",
    "cql_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MATCH (a)-[r0:RELATED_TO]->(b)\n",
    "MATCH (c)-[r1:RELATED_TO]->(g)\n",
    "MATCH (c)-[r2:RELATED_TO]->(e)\n",
    "MATCH (c)-[r3:RELATED_TO]->(g)\n",
    "MATCH (e)-[r4:RELATED_TO]->(g)\n",
    "WITH vector.similarity.cosine(a.embedding, $embed_a) as score_a, vector.similarity.cosine(r0.embedding, $embed_r0) as score_r0, vector.similarity.cosine(b.embedding, $embed_b) as score_b, vector.similarity.cosine(c.embedding, $embed_c) as score_c, vector.similarity.cosine(r1.embedding, $embed_r1) as score_r1, vector.similarity.cosine(g.embedding, $embed_g) as score_g, vector.similarity.cosine(r2.embedding, $embed_r2) as score_r2, vector.similarity.cosine(e.embedding, $embed_e) as score_e, vector.similarity.cosine(r3.embedding, $embed_r3) as score_r3, vector.similarity.cosine(r4.embedding, $embed_r4) as score_r4, a.id as id, a.feature as feature, a.app as app\n",
    "RETURN id, feature, app, (score_a+score_r0+score_b+score_c+score_r1+score_g+score_r2+score_e+score_r3+score_r4)/10 as score ORDER BY score DESC LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_embedding(text):\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    pooler_output = output['pooler_output'][0]\n",
    "    return pooler_output.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = {}\n",
    "for i in range(len(flatten)):\n",
    "    if flatten[i][0] == 'r':\n",
    "        verb = find_inverse_key(verbObj, flatten[i])\n",
    "        embedding[f\"embed_{flatten[i]}\"] = bert_embedding(verb)\n",
    "    else:\n",
    "        raw = find_inverse_key(entityObj, flatten[i])\n",
    "        entity = raw\n",
    "        embedding[f\"embed_{flatten[i]}\"] = bert_embedding(entity)\n",
    "embedding['app_name'] = app_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neo4j\n",
    "\n",
    "host = \"localhost\"\n",
    "username = \"neo4j\"\n",
    "password = \"1234qwer\"\n",
    "\n",
    "driver = neo4j.GraphDatabase.driver(f'bolt://localhost:7687', auth=(username, password))\n",
    "session = driver.session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, summary, key = driver.execute_query(cql_string, embedding)\n",
    "\n",
    "for row in records:   \n",
    "        print(row['id'], row['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
