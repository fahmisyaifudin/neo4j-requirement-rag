{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(X, y, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Prepare data for SVM classification\n",
    "    \n",
    "    Parameters:\n",
    "    - X: Feature matrix (embeddings)\n",
    "    - y: Target labels\n",
    "    - test_size: Proportion of test split\n",
    "    - random_state: Seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    - Train and test splits\n",
    "    \"\"\"\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=test_size, \n",
    "        random_state=random_state, \n",
    "        stratify=y  # Ensures balanced class distribution\n",
    "    )\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(X_train, y_train, kernel='rbf', C=1.0, random_state=42):\n",
    "    \"\"\"\n",
    "    Train SVM classifier\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: Scaled training features\n",
    "    - y_train: Training labels\n",
    "    - kernel: SVM kernel type\n",
    "    - C: Regularization parameter\n",
    "    \n",
    "    Returns:\n",
    "    - Trained SVM classifier\n",
    "    \"\"\"\n",
    "    svm_classifier = SVC(\n",
    "        kernel=kernel,  # 'linear', 'rbf', 'poly', 'sigmoid'\n",
    "        C=C,            # Regularization strength\n",
    "        random_state=random_state,\n",
    "        probability=True  # Enable probability estimates\n",
    "    )\n",
    "    \n",
    "    svm_classifier.fit(X_train, y_train)\n",
    "    return svm_classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_svm(classifier, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate SVM classifier\n",
    "    \n",
    "    Parameters:\n",
    "    - classifier: Trained SVM model\n",
    "    - X_test: Scaled test features\n",
    "    - y_test: Test labels\n",
    "    \n",
    "    Returns:\n",
    "    - Classification metrics\n",
    "    \"\"\"\n",
    "    # Predictions\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Detailed classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Cross-validation score\n",
    "    cv_scores = cross_val_score(classifier, X_test, y_test, cv=5)\n",
    "    print(f\"\\nCross-validation Scores: {cv_scores}\")\n",
    "    print(f\"Mean CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_svm_hyperparameters(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Perform grid search for SVM hyperparameter tuning\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: Scaled training features\n",
    "    - y_train: Training labels\n",
    "    \n",
    "    Returns:\n",
    "    - Best parameters\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'kernel': ['rbf', 'linear', 'poly'],\n",
    "        'gamma': ['scale', 'auto', 0.1, 1]\n",
    "    }\n",
    "    \n",
    "    # Grid Search\n",
    "    grid_search = GridSearchCV(\n",
    "        SVC(), \n",
    "        param_grid, \n",
    "        cv=5, \n",
    "        scoring='accuracy'\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Best Cross-validation Score:\", grid_search.best_score_)\n",
    "    \n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "def save_svm_model(classifier, scaler, model_path='svm_model.joblib', scaler_path='scaler.joblib'):\n",
    "    \"\"\"\n",
    "    Save the trained SVM model and its scaler\n",
    "    \n",
    "    Parameters:\n",
    "    - classifier: Trained SVM classifier\n",
    "    - scaler: Feature scaler used for preprocessing\n",
    "    - model_path: Path to save the SVM model\n",
    "    - scaler_path: Path to save the scaler\n",
    "    \"\"\"\n",
    "    # Save the SVM model\n",
    "    joblib.dump(classifier, model_path)\n",
    "    \n",
    "    # Save the scaler\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    \n",
    "    print(f\"Model saved to {model_path}\")\n",
    "    print(f\"Scaler saved to {scaler_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_svm_model(model_path='svm_model.joblib', scaler_path='scaler.joblib'):\n",
    "    \"\"\"\n",
    "    Load the saved SVM model and scaler\n",
    "    \n",
    "    Parameters:\n",
    "    - model_path: Path to the saved SVM model\n",
    "    - scaler_path: Path to the saved scaler\n",
    "    \n",
    "    Returns:\n",
    "    - Loaded SVM classifier\n",
    "    - Loaded scaler\n",
    "    \"\"\"\n",
    "    # Load the SVM model\n",
    "    classifier = joblib.load(model_path)\n",
    "    \n",
    "    # Load the scaler\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    \n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "    print(f\"Scaler loaded from {scaler_path}\")\n",
    "    \n",
    "    return classifier, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Function\n",
    "def predict_with_saved_model(new_embeddings, classifier, scaler):\n",
    "    \"\"\"\n",
    "    Make predictions using the saved model\n",
    "    \n",
    "    Parameters:\n",
    "    - new_embeddings: New data to predict (should be 1536-dimensional)\n",
    "    - classifier: Loaded SVM classifier\n",
    "    - scaler: Loaded scaler\n",
    "    \n",
    "    Returns:\n",
    "    - Predictions\n",
    "    - Prediction probabilities\n",
    "    \"\"\"\n",
    "\n",
    "     # Ensure input is 2D array\n",
    "    if new_embeddings.ndim == 1:\n",
    "        new_embeddings = new_embeddings.reshape(1, -1)\n",
    "        \n",
    "    # Scale the new data using the saved scaler\n",
    "    new_embeddings_scaled = scaler.transform(new_embeddings)\n",
    "    \n",
    "    # Predict classes\n",
    "    predictions = classifier.predict(new_embeddings_scaled)\n",
    "    \n",
    "    # Predict probabilities (if probability=True was set during training)\n",
    "    prediction_probs = classifier.predict_proba(new_embeddings_scaled)\n",
    "    \n",
    "    return predictions, prediction_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(X, y):\n",
    "    # Prepare data\n",
    "    X_train, X_test, y_train, y_test, scaler = prepare_data(X, y)\n",
    "    \n",
    "    # Optional: Hyperparameter Tuning\n",
    "    # best_classifier = tune_svm_hyperparameters(X_train, y_train)\n",
    "    \n",
    "    # Train SVM\n",
    "    svm_classifier = train_svm(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    evaluate_svm(svm_classifier, X_test, y_test)\n",
    "    \n",
    "    return svm_classifier, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_category(text):\n",
    "    \"\"\"\n",
    "    Map category text to corresponding integer value.\n",
    "    \n",
    "    Parameters:\n",
    "    - text: Category text\n",
    "    \n",
    "    Returns:\n",
    "    - Mapped integer value\n",
    "    \"\"\"\n",
    "    category_mapping = {\n",
    "        'CORE': 1,\n",
    "        'USER': 2,\n",
    "        'PLATFORM': 3,\n",
    "        'HARDWARE': 4\n",
    "    }\n",
    "    \n",
    "    return category_mapping.get(text, 1)\n",
    "\n",
    "def unmap_category(text):\n",
    "    \"\"\"\n",
    "    Map category text to corresponding integer value.\n",
    "    \n",
    "    Parameters:\n",
    "    - text: Category text\n",
    "    \n",
    "    Returns:\n",
    "    - Mapped integer value\n",
    "    \"\"\"\n",
    "    category_mapping = {\n",
    "        1: 'CORE',\n",
    "        2: 'USER',\n",
    "        3: 'PLATFORM',\n",
    "        4: 'HARDWARE'\n",
    "    }\n",
    "    \n",
    "    return category_mapping.get(text, 'CORE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fahmisyaifudin/miniconda3/envs/llm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def sentence_transformer_embedding(text):\n",
    "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    embeddings = model.encode(text)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fahmisyaifudin/miniconda3/envs/llm/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "llm_ner = pd.read_csv('data/all_ner_result.csv')\n",
    "entities = []\n",
    "label = []\n",
    "for i, row in llm_ner.iterrows():\n",
    "    entities.append(row['entity'])\n",
    "    label.append(map_category(row['category']))\n",
    "\n",
    "X = sentence_transformer_embedding(entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.98      0.96       277\n",
      "           2       0.98      0.96      0.97       112\n",
      "           3       0.84      0.73      0.78        22\n",
      "           4       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.95       421\n",
      "   macro avg       0.88      0.82      0.84       421\n",
      "weighted avg       0.95      0.95      0.95       421\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[271   2   2   2]\n",
      " [  5 107   0   0]\n",
      " [  6   0  16   0]\n",
      " [  3   0   1   6]]\n",
      "\n",
      "Cross-validation Scores: [0.91764706 0.92857143 0.9047619  0.89285714 0.94047619]\n",
      "Mean CV Score: 0.9169 (+/- 0.0337)\n"
     ]
    }
   ],
   "source": [
    "classifier, scaler = main(X, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to svm_model.joblib\n",
      "Scaler saved to scaler.joblib\n"
     ]
    }
   ],
   "source": [
    "save_svm_model(classifier, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neo4j\n",
    "\n",
    "host = \"localhost\"\n",
    "username = \"neo4j\"\n",
    "password = \"1234qwer\"\n",
    "\n",
    "# driver = neo4j.GraphDatabase.driver(\"neo4j://100.27.33.222:7687\",\n",
    "#   auth=neo4j.basic_auth(\"neo4j\", \"price-oxygens-scores\")\n",
    "# )\n",
    "driver = neo4j.GraphDatabase.driver(f'bolt://localhost:7687', auth=(username, password))\n",
    "session = driver.session()\n",
    "\n",
    "def create_graph(query):\n",
    "    session.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fahmisyaifudin/miniconda3/envs/llm/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "records, summary, key = driver.execute_query(\"\"\"\n",
    "MATCH (n:CORE) RETURN n.name\"\"\")\n",
    "core_entities = []\n",
    "for record in records:\n",
    "    name = record['n.name']\n",
    "    core_entities.append(name)\n",
    "\n",
    "embeddings = sentence_transformer_embedding(core_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from svm_model.joblib\n",
      "Scaler loaded from scaler.joblib\n"
     ]
    }
   ],
   "source": [
    "loaded_classifier, loaded_scaler = load_svm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(core_entities)):\n",
    "    predictions, _ = predict_with_saved_model(embeddings[i], loaded_classifier, loaded_scaler)\n",
    "    session.run(f\"\"\"\n",
    "    MATCH (n:CORE)\n",
    "    WHERE n.name = $name\n",
    "    SET n:{unmap_category(predictions[0])} RETURN n.name, labels(n) as labels\n",
    "    \"\"\", name=core_entities[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
